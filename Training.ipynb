{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a90304f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:14:08.149265Z",
     "start_time": "2025-10-03T13:14:01.171894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py311/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py311/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import webbrowser\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import datasets\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from jaxtyping import Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n",
    "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
    "\n",
    "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda:0\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c76731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:16:49.513984Z",
     "start_time": "2025-10-03T13:16:48.450416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.53.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_config = GPT2Config.from_pretrained(\"gpt2\")\n",
    "print(gpt2_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565cd37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:15:02.793919Z",
     "start_time": "2025-10-03T13:15:02.779427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # gpt2-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0770f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:13:31.121990Z",
     "start_time": "2025-10-03T13:13:27.505717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# reference_gpt2 = HookedTransformer.from_pretrained(\n",
    "#     \"gpt2-small\",\n",
    "#     fold_ln=False,\n",
    "#     center_unembed=False,\n",
    "#     center_writing_weights=False,  # you'll learn about these arguments later!\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202983a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:15:24.604127Z",
     "start_time": "2025-10-03T13:15:24.592063Z"
    }
   },
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class Config:\n",
    "#     d_model: int = 768\n",
    "#     debug: bool = True\n",
    "#     layer_norm_eps: float = 1e-5\n",
    "#     d_vocab: int = 50257\n",
    "#     init_range: float = 0.02\n",
    "#     n_ctx: int = 1024\n",
    "#     d_head: int = 64\n",
    "#     d_mlp: int = 3072\n",
    "#     n_heads: int = 12\n",
    "#     n_layers: int = 12\n",
    "\n",
    "# model_cfg = Config(\n",
    "#     debug=False,\n",
    "#     d_model=256,\n",
    "#     n_heads=4,\n",
    "#     d_head=64,\n",
    "#     d_mlp=1024,\n",
    "#     n_layers=2,\n",
    "#     n_ctx=256,\n",
    "#     d_vocab=reference_gpt2.cfg.d_vocab,\n",
    "# )\n",
    "# # model = DemoTransformer(model_cfg)\n",
    "\n",
    "@dataclass\n",
    "class TransformerTrainingArgs:\n",
    "    batch_size = 16\n",
    "    epochs = 20\n",
    "    max_steps_per_epoch = 200\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-2\n",
    "    wandb_project: str | None = \"transformer\"\n",
    "    wandb_name: str | None = None\n",
    "\n",
    "\n",
    "args = TransformerTrainingArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4d81a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-03T13:17:30.949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a35a790fd4883b1b40def1235fddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create datasets\n",
    "\n",
    "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\").remove_columns(\"meta\")\n",
    "print(dataset)\n",
    "print(dataset[0][\"text\"][:100])\n",
    "\n",
    "tokenized_dataset = tokenize_and_concatenate(\n",
    "    dataset,\n",
    "#     reference_gpt2.tokenizer,\n",
    "    tokenizer,\n",
    "    streaming=False,\n",
    "#     max_length=reference_gpt2.cfg.n_ctx,\n",
    "    max_length=gpt2_config.n_ctx,\n",
    "    column_name=\"text\",\n",
    "    add_bos_token=True,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "dataset_dict = tokenized_dataset.train_test_split(test_size=1000)\n",
    "train_loader = DataLoader(\n",
    "    dataset_dict[\"train\"], batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_dict[\"test\"], batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f307c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-03T13:17:41.221Z"
    }
   },
   "outputs": [],
   "source": [
    "first_batch = train_loader.dataset[: args.batch_size]\n",
    "\n",
    "print(first_batch.keys())\n",
    "print(first_batch[\"tokens\"].shape)\n",
    "\n",
    "# find dictionaries with the single key 'tokens', which maps to a tensor of token IDs with shape (batch, seq_len)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b049815",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1dc6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-03T13:17:46.894Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerTrainer:\n",
    "    def __init__(self, args: TransformerTrainingArgs, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.args = args\n",
    "\n",
    "        self.wandb = False\n",
    "\n",
    "        self.optimizer = t.optim.AdamW(self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "        self.step = 0\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            dataset_dict[\"train\"], batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            dataset_dict[\"test\"], batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: dict[str, Int[Tensor, \"batch seq\"]]) -> Float[Tensor, \"\"]:\n",
    "        \"\"\"\n",
    "        Calculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
    "\n",
    "        Remember that `batch` is a dictionary with the single key 'tokens'.\n",
    "        \"\"\"\n",
    "        # raise NotImplementedError()\n",
    "        tokens = batch[\"tokens\"].to(device) # shape (batch, seq)  \n",
    "\n",
    "        logits = self.model(tokens) # shape (batch, seq) \n",
    "        loss = -get_log_probs(logits, tokens) # shape (batch, seq - 1)\n",
    "\n",
    "        loss = loss.mean() # mean across all dimensions\n",
    "        # what loss? CrossEntropy. Note: no \"label\" here. The fitting objective is the batch\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        self.step += 1\n",
    "        if self.wandb:\n",
    "            wandb.log({'train_loss': loss}, step = self.step)\n",
    "        return loss\n",
    "\n",
    "    @t.inference_mode()\n",
    "    def evaluate(self) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model on the test set and return the accuracy.\n",
    "        \"\"\"\n",
    "        self.model.eval() # go eval mode\n",
    "        # YOUR CODE HERE - fill in the `evaluate` method\n",
    "        progress_bar = tqdm(self.test_loader, desc=\"Evaluating\")\n",
    "        \n",
    "        acc = []\n",
    "        # no epoch\n",
    "        for batch in progress_bar:\n",
    "            tokens = batch[\"tokens\"].to(device) # shape (batch, seq)  \n",
    "            logits = self.model(tokens)[:, :-1, ]  # shape (batch, seq-1, d_voc)  \n",
    "            # Why seq-1: the last position has no label——the next token in the sequence\n",
    "            preds = logits.argmax(dim=-1)  # shape (batch, seq-1)  \n",
    "            # print(t.where(preds == batch, preds, 0).shape)\n",
    "            # wrong = t.where(preds == batch, preds, 0).sum()  \n",
    "            correct = (preds == tokens[:, 1:]).sum().item() # summing across both batch and (seq-1) dimensions\n",
    "            n_samples = tokens.shape[0] * (tokens.shape[1] - 1)\n",
    "            accuracy = correct / n_samples\n",
    "\n",
    "            progress_bar.update()\n",
    "            progress_bar.set_description(f\"accuracy so far: {np.mean(acc):.3f}\")\n",
    "\n",
    "            if self.wandb:\n",
    "                wandb.log({'accuracy': accuracy}, step = self.step)\n",
    "            acc.append(accuracy)\n",
    "        if self.wandb:       \n",
    "            wandb.finish()\n",
    "\n",
    "        self.model.train() # go back to train mode\n",
    "\n",
    "        return np.mean(acc)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the model, for `self.args.epochs` epochs. Also handles wandb initialisation, and early stopping\n",
    "        for each epoch at `self.args.max_steps_per_epoch` steps.\n",
    "        \"\"\"\n",
    "        if self.wandb:\n",
    "            wandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
    "        accuracy = np.nan\n",
    "\n",
    "        progress_bar = tqdm(total=self.args.max_steps_per_epoch * self.args.epochs)\n",
    "\n",
    "        for epoch in range(self.args.epochs):\n",
    "            for i, batch in enumerate(self.train_loader):\n",
    "                loss = self.training_step(batch)\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description(f\"Epoch {epoch + 1}, loss: {loss:.3f}, accuracy: {accuracy:.3f}\")\n",
    "                if i >= self.args.max_steps_per_epoch:\n",
    "                    break\n",
    "\n",
    "            accuracy = self.evaluate()\n",
    "        if self.wandb == True:\n",
    "            wandb.finish()\n",
    "\n",
    "\n",
    "# model = reference_gpt2(model_cfg).to(device)\n",
    "model = model.to(device)\n",
    "args = TransformerTrainingArgs()\n",
    "trainer = TransformerTrainer(args, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dfe21",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-10-03T13:17:48.544Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e3662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T13:13:36.863430Z",
     "start_time": "2025-10-03T13:13:36.863421Z"
    }
   },
   "outputs": [],
   "source": [
    "# first iteration: get the training baseline running and wandb in notebook correctly configured. \n",
    "# If the latter failed, try to log manually"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
